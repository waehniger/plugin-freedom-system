# DSP Architecture: Sektor

**CRITICAL CONTRACT:** This specification is immutable during Stages 1-4 implementation. Stage 1 Planning cannot proceed without this file. Stage 3 (DSP) implements this exact architecture.

**Generated by:** Stage 0 Research
**Referenced by:** Stage 1 (Planning), Stage 3 (DSP Implementation)
**Purpose:** DSP specification defining granular sampler processing components, signal flow, and JUCE module usage

---

## Core Components

### Sample Buffer Manager
- **JUCE Class:** Custom implementation using `juce::AudioBuffer<float>` for storage
- **Purpose:** Load and manage audio sample data in memory
- **Parameters Affected:** None (loaded via file I/O, not APVTS parameters)
- **Configuration:**
  - Single AudioBuffer per plugin instance (monophonic or stereo sample)
  - Maximum sample length: 60 seconds at 192kHz (~11.5M samples per channel)
  - Stores raw sample data for granular extraction
  - Handles sample rate conversion if needed (target rate = host rate)

### Region Selector
- **JUCE Class:** Custom implementation (normalized position tracking)
- **Purpose:** Define playback region within loaded sample
- **Parameters Affected:** REGION_START, REGION_END
- **Configuration:**
  - REGION_START (0.0-1.0 normalized) → sample position in frames
  - REGION_END (0.0-1.0 normalized) → sample position in frames
  - Conversion: `samplePosition = normalizedValue * totalSampleFrames`
  - Validation: Ensure REGION_END > REGION_START (minimum 10ms region length)
  - Default: Full sample (0.0 to 1.0)

### Granular Engine
- **JUCE Class:** Custom implementation with `juce::dsp::WindowingFunction<float>` for grain windowing
- **Purpose:** Extract and render overlapping grains from marked region with pitch shifting and spacing control
- **Parameters Affected:** GRAIN_SIZE, DENSITY, PITCH_SHIFT, SPACING
- **Configuration:**
  - **Grain Size:** 10-500ms → converted to sample count: `grainSamples = (grainSizeMs / 1000.0) * sampleRate`
  - **Density:** 1-200 grains/sec → spacing between grain triggers: `grainInterval = sampleRate / density`
  - **Pitch Shift:** -12 to +12 semitones → playback rate: `rate = pow(2.0, semitones / 12.0)`
  - **Spacing:** 0.1-2.0 → grain position increment multiplier (affects grain overlap and texture)
  - **Window Function:** Hann window (`juce::dsp::WindowingFunction<float>::hann`) applied to each grain to prevent clicks
  - **Overlap Strategy:** Density controls grain trigger rate, spacing controls grain position advancement
  - **Grain Extraction:** Read from region (REGION_START to REGION_END) with looping

### Voice Manager
- **JUCE Class:** Custom polyphonic voice allocator (similar to `juce::Synthesiser` pattern)
- **Purpose:** Manage polyphonic MIDI note playback with independent granular streams per voice
- **Parameters Affected:** POLYPHONY_MODE
- **Configuration:**
  - **Max Voices:** 16 voices (typical polyphonic sampler standard)
  - **Voice Allocation:** Round-robin with note-off stealing for oldest voice
  - **Polyphony Mode:**
    - Mono (false): Single voice, last note priority, no voice stealing
    - Poly (true): Up to 16 simultaneous voices
  - **Per-Voice State:**
    - MIDI note number (for pitch tracking)
    - Grain phase (current position in grain extraction)
    - Grain envelope state (attack/release for voice on/off)
    - Velocity (scales output gain 0.0-1.0)
  - **Note Handling:**
    - Note-on: Allocate voice, reset grain phase to region start
    - Note-off: Trigger release envelope (10ms fade-out to prevent clicks)

### Pitch Shifter
- **JUCE Class:** Custom implementation via sample rate manipulation (time-domain approach)
- **Purpose:** Transpose grain playback without changing grain size
- **Parameters Affected:** PITCH_SHIFT
- **Configuration:**
  - **Algorithm:** Playback rate adjustment with linear interpolation
  - **Pitch Shift Range:** -12 to +12 semitones
  - **Rate Calculation:** `playbackRate = pow(2.0, semitones / 12.0)`
    - 0 semitones → 1.0x rate (no shift)
    - +12 semitones → 2.0x rate (one octave up)
    - -12 semitones → 0.5x rate (one octave down)
  - **Interpolation:** Linear interpolation for fractional sample reads (balance quality vs CPU)
  - **Integration:** Applied during grain extraction (read position advances by `playbackRate` instead of 1.0)

### Output Mixer
- **JUCE Class:** Custom gain staging
- **Purpose:** Sum all active voices and apply final output gain
- **Parameters Affected:** None (voices pre-scaled by MIDI velocity)
- **Configuration:**
  - Sum all active voice outputs
  - No dry/wet mix (instrument produces audio from scratch, no input signal)
  - Normalization: Scale by `1.0 / sqrt(maxVoices)` to prevent clipping with many voices (~0.25 for 16 voices)
  - Soft clipping: Apply `tanh()` if signal exceeds ±1.0 (prevents harsh digital clipping)

---

## Processing Chain

```
MIDI Input (Note On/Off)
  ↓
Voice Allocator ← POLYPHONY_MODE parameter
  ↓
[Per Voice Processing - Up to 16 parallel streams]
  ↓
Grain Generator ← GRAIN_SIZE, DENSITY, SPACING parameters
  ├─ Extract grain from Sample Buffer
  ├─ Region bounds: REGION_START to REGION_END
  ├─ Apply Hann window to grain
  ├─ Pitch shift via playback rate ← PITCH_SHIFT parameter
  └─ Output grain samples
  ↓
Voice Envelope (Note On: instant attack, Note Off: 10ms release)
  ↓
Velocity Scaling (MIDI velocity 0-127 → gain 0.0-1.0)
  ↓
[Sum All Voices]
  ↓
Output Mixer (normalization + soft clipping)
  ↓
Stereo Output
```

**Routing notes:**
- No audio input (instrument synthesizes from loaded sample)
- Each voice runs independent granular stream (no shared grain state)
- All voices sum at output (no per-voice routing, single stereo output)
- Sample loading happens on background thread (not in audio processing chain)

---

## System Architecture

### File I/O System

**File types supported:** .wav, .aiff, .flac, .mp3 (via macOS system codecs)

**Loading strategy:** Background thread loading with atomic buffer swap
- File selection happens via UI button click or drag-and-drop
- Sample loading runs on background thread (`juce::Thread::launch()`)
- Audio thread continues playing current sample (or silence if no sample loaded)
- On load complete, atomic pointer swap to new sample buffer
- Old buffer deleted on message thread (safe disposal)

**JUCE classes:**
- `juce::File` - File path management
- `juce::AudioFormatManager` - Format detection and codec registration
  - `registerBasicFormats()` registers WAV, AIFF
  - System codecs handle FLAC, MP3 on macOS
- `juce::AudioFormatReader` - Audio file reading into memory
- `juce::FileChooser` - Native file browser dialog
- `juce::FileDragAndDropTarget` - Drag-and-drop handling in WebView

**Thread safety:**
- File I/O operations run on background thread (via `std::async` or `juce::Thread`)
- Communication with audio thread via `std::atomic<AudioBuffer<float>*>` pointer swap
- Audio thread reads from current buffer pointer (lock-free access)
- Background thread loads to temporary buffer, then atomic swap
- No mutex needed (atomic pointer operations are lock-free)

**Error handling:**
- Missing file on restore: Show "No Sample Loaded" in UI, plugin silent until sample loaded
- Invalid format: Show error message in UI ("Unsupported file format"), maintain previous sample
- Read failure: Log error to console, show error in UI, maintain previous sample
- File too large (>60s): Truncate to 60s, show warning in UI

**Sample Rate Conversion:**
- If sample rate != host rate: Use `juce::LagrangeInterpolator` to resample on load
- Target rate = host sample rate (from `prepareToPlay`)
- Resampling happens during load (not real-time), ensures grain extraction uses correct timing

---

### MIDI Routing

**Input handling:** Omni mode (responds to all MIDI channels)

**Note mapping:**
- **All MIDI notes (0-127)**: Trigger granular playback at base pitch
- **Pitch shift:** PITCH_SHIFT parameter transposes ALL notes equally
  - Example: MIDI C3 (note 60) + PITCH_SHIFT +5 semitones = F3 playback
- **Velocity:** Affects voice output gain (0-127 → 0.0-1.0 linear scaling)
- **Note priority (Mono mode):** Last-note priority (new note-on steals voice)
- **Polyphony (Poly mode):** Up to 16 simultaneous voices, round-robin allocation

**JUCE classes:**
- `juce::MidiBuffer` - MIDI event storage and iteration
- `juce::MidiMessage::isNoteOn()` - Detect note-on events
- `juce::MidiMessage::isNoteOff()` - Detect note-off events
- `juce::MidiMessage::getNoteNumber()` - Extract MIDI note (0-127)
- `juce::MidiMessage::getVelocity()` - Extract velocity (0-127)

**Processing:**
```cpp
for (const auto metadata : midiMessages)
{
    auto message = metadata.getMessage();
    int samplePosition = metadata.samplePosition; // For sample-accurate timing

    if (message.isNoteOn())
    {
        int noteNumber = message.getNoteNumber();
        float velocity = message.getVelocity() / 127.0f;

        // Allocate voice (mono: steal current, poly: find free or steal oldest)
        Voice* voice = allocateVoice(noteNumber);
        voice->startNote(noteNumber, velocity, samplePosition);
    }
    else if (message.isNoteOff())
    {
        int noteNumber = message.getNoteNumber();

        // Find voice playing this note and trigger release
        Voice* voice = findVoiceForNote(noteNumber);
        if (voice != nullptr)
            voice->stopNote(samplePosition);
    }
}
```

**Special Considerations:**
- **Sample-accurate timing:** MIDI events processed at exact sample position within buffer
- **Mono legato:** In mono mode, note-on while voice active = retrigger grain phase (no release)
- **All-notes-off:** MIDI CC 123 (all notes off) triggers release for all voices

---

### State Persistence

**What state is saved:**
- **APVTS parameters:** GRAIN_SIZE, DENSITY, PITCH_SHIFT, SPACING, REGION_START, REGION_END, POLYPHONY_MODE (automatic)
- **Custom state:**
  - Loaded sample file path (absolute path as string)
  - Sample buffer data (optional: embed sample in preset vs reference file)

**Serialization format:**
- APVTS parameters: Automatic via `AudioProcessorValueTreeState` (XML in ValueTree)
- Custom state: ValueTree structure:
  ```
  <SektorState>
    <Sample filePath="/absolute/path/to/sample.wav" embedData="false"/>
  </SektorState>
  ```
- **Optional embedding:** If `embedData="true"`, serialize sample buffer as Base64 in ValueTree (increases preset size but ensures portability)

**JUCE classes:**
- `juce::AudioProcessorValueTreeState` - APVTS automatic persistence
- `juce::ValueTree` - Custom state tree for sample path
- `juce::ValueTree::toXmlString()` - Serialize to XML
- `juce::ValueTree::fromXml()` - Deserialize from XML
- `juce::MemoryBlock` - For Base64 encoding if embedding sample data

**Save/restore methods:**
```cpp
void getStateInformation(MemoryBlock& destData) override
{
    // Get APVTS state
    auto state = parameters.copyState();

    // Add custom state
    juce::ValueTree customState("SektorState");
    customState.setProperty("filePath", currentSamplePath.getFullPathName(), nullptr);
    customState.setProperty("embedData", false, nullptr); // Don't embed by default

    state.appendChild(customState, nullptr);

    // Serialize to memory block
    std::unique_ptr<juce::XmlElement> xml(state.createXml());
    copyXmlToBinary(*xml, destData);
}

void setStateInformation(const void* data, int sizeInBytes) override
{
    // Deserialize
    std::unique_ptr<juce::XmlElement> xmlState(getXmlFromBinary(data, sizeInBytes));

    if (xmlState != nullptr)
    {
        auto state = juce::ValueTree::fromXml(*xmlState);

        // Restore APVTS parameters
        parameters.replaceState(state);

        // Restore custom state
        auto customState = state.getChildWithName("SektorState");
        if (customState.isValid())
        {
            juce::String filePath = customState.getProperty("filePath");
            if (juce::File(filePath).existsAsFile())
            {
                loadSampleAsync(juce::File(filePath)); // Background thread load
            }
            else
            {
                // File missing - show error in UI
                currentSamplePath = juce::File();
            }
        }
    }
}
```

**Restore behavior:**
- **File path doesn't exist:** Show "Sample Not Found" in UI, plugin silent until user loads new sample
- **Invalid XML:** Use default APVTS values, no sample loaded, log error
- **Embedded data:** If `embedData="true"`, decode Base64 sample data and load into buffer (no file I/O)
- **Version migration:** Future versions check ValueTree property "version" for compatibility handling

---

## Parameter Mapping

| Parameter ID | Type | Range | DSP Component | Usage |
|-------------|------|-------|---------------|-------|
| GRAIN_SIZE | Float | 10-500 ms | Granular Engine | Grain length in samples: `grainSamples = (value / 1000.0) * sampleRate` |
| DENSITY | Float | 1-200 grains/sec | Granular Engine | Grain trigger interval: `interval = sampleRate / value` |
| PITCH_SHIFT | Float | -12 to +12 semitones | Pitch Shifter | Playback rate: `rate = pow(2.0, value / 12.0)` |
| SPACING | Float | 0.1-2.0 | Granular Engine | Grain position increment multiplier (controls overlap and texture) |
| REGION_START | Float | 0.0-1.0 (normalized) | Region Selector | Sample position: `startFrame = value * totalSampleFrames` |
| REGION_END | Float | 0.0-1.0 (normalized) | Region Selector | Sample position: `endFrame = value * totalSampleFrames` |
| POLYPHONY_MODE | Bool | false/true | Voice Manager | Mono (false) or Poly (true) |

---

## Algorithm Details

### Granular Synthesis

**Algorithm:** Overlap-add synthesis with windowed grains extracted from sample buffer

**Core Concept:**
- Extract short segments (grains) from sample buffer at regular intervals (density)
- Apply window function (Hann) to each grain to prevent clicks
- Advance grain extraction position by spacing multiplier
- Overlap grains to create continuous output texture

**Implementation notes:**

**Grain Extraction:**
```cpp
// Per-voice grain generation (called at grain trigger interval)
void Voice::generateGrain()
{
    // Calculate grain size in samples
    int grainSamples = static_cast<int>((grainSizeMs / 1000.0f) * sampleRate);

    // Get current grain read position within region
    int regionStartFrame = static_cast<int>(regionStart * sampleBuffer.getNumSamples());
    int regionEndFrame = static_cast<int>(regionEnd * sampleBuffer.getNumSamples());
    int regionLength = regionEndFrame - regionStartFrame;

    // Current grain position (wraps at region end)
    int grainStartPos = regionStartFrame + (grainPhase % regionLength);

    // Extract grain samples with pitch shift (playback rate)
    float pitchRate = std::pow(2.0f, pitchShiftSemitones / 12.0f);
    float readPosition = 0.0f;

    for (int i = 0; i < grainSamples; ++i)
    {
        // Linear interpolation for fractional sample reads
        int sampleIndex = grainStartPos + static_cast<int>(readPosition);
        float frac = readPosition - static_cast<int>(readPosition);

        // Wrap at region boundary
        if (sampleIndex >= regionEndFrame)
            sampleIndex = regionStartFrame + (sampleIndex - regionStartFrame) % regionLength;

        int nextIndex = sampleIndex + 1;
        if (nextIndex >= regionEndFrame)
            nextIndex = regionStartFrame;

        // Linear interpolation
        float sample1 = sampleBuffer.getSample(0, sampleIndex);
        float sample2 = sampleBuffer.getSample(0, nextIndex);
        float interpolated = sample1 + frac * (sample2 - sample1);

        // Apply Hann window
        float windowValue = hannWindow[i]; // Pre-calculated Hann window
        grainBuffer[i] = interpolated * windowValue;

        // Advance read position by pitch rate
        readPosition += pitchRate;
    }

    // Advance grain phase for next grain
    grainPhase += static_cast<int>(grainSamples * spacingMultiplier);
}
```

**Hann Window Generation:**
```cpp
void prepareHannWindow(int grainSize)
{
    hannWindow.resize(grainSize);
    for (int i = 0; i < grainSize; ++i)
    {
        // Hann window formula: 0.5 * (1 - cos(2π * i / (N-1)))
        float phase = juce::MathConstants<float>::twoPi * i / (grainSize - 1);
        hannWindow[i] = 0.5f * (1.0f - std::cos(phase));
    }
}
```

**Grain Triggering (Density Control):**
```cpp
void Voice::processBlock(AudioBuffer<float>& output, int numSamples)
{
    int samplesUntilNextGrain = nextGrainTriggerSample - currentSamplePosition;

    for (int sample = 0; sample < numSamples; ++sample)
    {
        // Check if we need to trigger new grain
        if (samplesUntilNextGrain <= 0)
        {
            generateGrain(); // Create new grain

            // Calculate next grain trigger time (based on density)
            int grainInterval = static_cast<int>(sampleRate / density); // density = grains/sec
            nextGrainTriggerSample += grainInterval;
            samplesUntilNextGrain = grainInterval;
        }

        // Mix all active grains for this sample
        float outputSample = 0.0f;
        for (auto& grain : activeGrains)
        {
            if (grain.isActive())
                outputSample += grain.getNextSample();
        }

        // Write to output buffer
        output.setSample(0, sample, outputSample * velocityGain);

        --samplesUntilNextGrain;
    }
}
```

**Spacing Multiplier:**
- Controls how fast grain extraction position advances
- `spacing = 1.0`: Normal advancement (grain size determines position increment)
- `spacing < 1.0`: Slower advancement (more grain overlap, denser texture)
- `spacing > 1.0`: Faster advancement (less overlap, more granular texture, potential gaps)
- Formula: `grainPhase += grainSamples * spacing`

**CPU Optimization:**
- Pre-calculate Hann window tables for common grain sizes
- Limit max active grains per voice (e.g., 8 grains max)
- Use fixed-point arithmetic for grain phase tracking (faster than float modulo)
- SIMD optimization for grain windowing (process 4 samples at once)

---

### Pitch Shifting via Time-Domain Stretching

**Algorithm:** Playback rate adjustment with linear interpolation

**Why Time-Domain (Not Frequency-Domain):**
- Granular synthesis inherently handles pitch shift via grain playback rate
- No need for complex phase vocoder (FFT/IFFT overhead)
- Grain windowing prevents artifacts that would occur with simple rate change
- Lower CPU cost than FFT-based approaches (~5% vs ~40% single core)

**Playback Rate Calculation:**
```cpp
// Semitones to playback rate (standard tuning formula)
float pitchRate = std::pow(2.0f, semitones / 12.0f);

// Examples:
// +12 semitones → 2.0x rate (one octave up)
//   0 semitones → 1.0x rate (no pitch shift)
// -12 semitones → 0.5x rate (one octave down)
//  +7 semitones → 1.498x rate (perfect fifth up)
```

**Linear Interpolation:**
```cpp
// Fractional sample read with linear interpolation
float readFractionalSample(const AudioBuffer<float>& buffer, int channel, float position)
{
    int index1 = static_cast<int>(position);
    int index2 = index1 + 1;
    float frac = position - index1;

    // Wrap indices at buffer boundary
    index1 = index1 % buffer.getNumSamples();
    index2 = index2 % buffer.getNumSamples();

    float sample1 = buffer.getSample(channel, index1);
    float sample2 = buffer.getSample(channel, index2);

    return sample1 + frac * (sample2 - sample1);
}
```

**Quality vs Performance Trade-off:**
- **Linear interpolation:** Fastest, minimal CPU, acceptable quality for granular (grain windowing masks artifacts)
- **Cubic/Lagrange interpolation:** Higher quality, 2-3x CPU cost, smoother pitch shift
- **Decision:** Use linear for initial implementation, add cubic as optional quality mode if needed

---

### Voice Management and Polyphony

**Voice Allocation (Poly Mode):**
```cpp
Voice* VoiceManager::allocateVoice(int noteNumber)
{
    // 1. Find free voice (not currently playing)
    for (auto& voice : voices)
    {
        if (!voice.isPlaying())
        {
            return &voice;
        }
    }

    // 2. No free voices - steal oldest voice
    Voice* oldestVoice = &voices[0];
    int oldestAge = 0;

    for (auto& voice : voices)
    {
        if (voice.getAge() > oldestAge)
        {
            oldestAge = voice.getAge();
            oldestVoice = &voice;
        }
    }

    // Trigger fast release on stolen voice (10ms fade-out)
    oldestVoice->triggerQuickRelease();

    return oldestVoice;
}
```

**Voice State Machine:**
```
IDLE → NOTE_ON → PLAYING → NOTE_OFF → RELEASING → IDLE
  ↑                                               ↓
  └───────────────────────────────────────────────┘
```

**Mono Mode Implementation:**
```cpp
void VoiceManager::handleNoteOn_MonoMode(int noteNumber, float velocity)
{
    // Always use voice[0] in mono mode
    Voice& monoVoice = voices[0];

    if (monoVoice.isPlaying())
    {
        // Legato: Retrigger grain phase without release
        monoVoice.retrigger(noteNumber, velocity);
    }
    else
    {
        // Fresh note start
        monoVoice.startNote(noteNumber, velocity);
    }
}
```

**Voice Envelope (Simple Attack/Release):**
```cpp
void Voice::processEnvelope()
{
    if (state == PLAYING)
    {
        // Instant attack (envelope = 1.0)
        envelopeLevel = 1.0f;
    }
    else if (state == RELEASING)
    {
        // 10ms release to prevent clicks
        float releaseRate = 1.0f / (0.01f * sampleRate); // 10ms in samples
        envelopeLevel -= releaseRate;

        if (envelopeLevel <= 0.0f)
        {
            envelopeLevel = 0.0f;
            state = IDLE;
        }
    }
}
```

---

## Integration Points

### Feature Dependencies

- **Sample loading → Granular engine:** Must load sample before granular extraction possible
- **Region selection → Granular engine:** Region bounds define grain extraction area
- **MIDI input → Voice allocation:** MIDI note-on triggers voice allocation and grain playback
- **Voice management → Output mixer:** All voices sum at output (voice outputs are inputs to mixer)
- **Pitch shift → Grain extraction:** Pitch rate affects grain playback speed (integrated into grain read loop)

---

### Parameter Interactions

- **Grain Size + Density:** Control grain overlap texture
  - Small grain + high density → Dense, smooth texture (many short grains overlapping)
  - Large grain + low density → Sparse, granular texture (few long grains with gaps)
  - Formula: Overlap factor = `(grainSize * density) / 1000.0` (>1.0 = overlapping)

- **Pitch Shift + Grain Size:** Pitch shift doesn't change grain duration
  - +12 semitones: Grain plays 2x faster but still triggers at same density
  - Grain size is time-based (milliseconds), not sample-based
  - Result: Higher pitches sound "thinner" (fewer samples per grain at higher pitch rates)

- **Spacing + Density:** Both affect grain overlap but via different mechanisms
  - Density: Controls trigger rate (how often new grains start)
  - Spacing: Controls position advancement (where in sample each grain reads from)
  - High density + low spacing → Many grains reading similar sample positions (chorus-like)
  - Low density + high spacing → Few grains reading far-apart positions (sparse, jumpy)

- **Region Start/End + All Parameters:** Region bounds affect all grain extraction
  - Changing region while playing → Grain positions recalculate on next grain trigger
  - Small region (<100ms) + large grain size → Grains loop within region (stutter effect)
  - Region length affects spacing behavior (spacing is relative to grain size, not region size)

- **Polyphony Mode + CPU Usage:**
  - Mono mode: 1 voice active max → Minimal CPU (~5-10% single core)
  - Poly mode: Up to 16 voices active → Higher CPU (~50-80% single core with all voices active)
  - CPU scales linearly with active voices (each voice is independent granular stream)

---

### Processing Order Requirements

**Sequential processing order (per audio buffer):**

1. **Process MIDI messages:** Iterate MIDI buffer, handle note-on/note-off events
   - Must happen first (establishes which voices are active for this buffer)

2. **Update voice states:** Allocate/release voices based on MIDI events
   - Note-on: Allocate voice, reset grain phase
   - Note-off: Trigger release envelope

3. **Read APVTS parameters:** Get current parameter values (atomic reads)
   - GRAIN_SIZE, DENSITY, PITCH_SHIFT, SPACING, REGION_START, REGION_END
   - Happens before voice processing (voices use these values)

4. **Per-voice processing (parallel):** Each voice generates its output independently
   - Check grain trigger timing (density-based interval)
   - Generate new grains as needed (grain extraction with pitch shift)
   - Mix active grains for this voice
   - Apply velocity scaling
   - No inter-voice dependencies (can be parallelized if needed)

5. **Sum all voices:** Mix all voice outputs to single stereo buffer
   - Simple addition: `output += voice.output * voiceGain`
   - Normalization: `voiceGain = 1.0 / sqrt(maxVoices)` (~0.25 for 16 voices)

6. **Apply soft clipping:** Prevent output from exceeding ±1.0
   - `output = tanh(output)` if `abs(output) > 0.95`
   - Smooth saturation instead of hard clipping

7. **Write to output buffer:** Final stereo output to host

**Why order matters:**
- MIDI must process first (determines voice activity)
- Parameter reads before voice processing (voices use current values)
- Voice summing before clipping (clipping needs final mixed signal)
- No dry signal (instrument generates from scratch, no input to preserve)

**Parallel processing opportunities:**
- Each voice processes independently (can use thread pool for voice rendering if needed)
- Grain generation can be multi-threaded (each voice has own grain buffer)
- Not critical for initial implementation (CPU profiling will determine if parallelization needed)

---

### Thread Boundaries

**Threads:**
- **Audio thread:** Real-time grain processing in `processBlock()` - NO allocations, NO locks, NO file I/O
- **Message thread:** UI interactions (parameter changes, file browser clicks)
- **Background thread:** Sample loading, file I/O

**Audio thread operations:**
- Read from sample buffer pointer (atomic load, lock-free)
- Read APVTS parameters (atomic, provided by JUCE)
- Generate grains (pure computation, no allocations)
- Process MIDI events (iterate JUCE MidiBuffer)
- Sum voices and write output

**Message thread operations:**
- Parameter updates via APVTS (atomic writes)
- File browser dialog (`juce::FileChooser`)
- Drag-and-drop file handling
- UI repaints and WebView updates
- Trigger background sample load

**Background thread operations:**
- File I/O via `juce::AudioFormatReader` (blocking, can take 10-500ms)
- Sample rate conversion if needed
- Create new `AudioBuffer<float>` with loaded data
- Atomic pointer swap to make new buffer visible to audio thread

**Communication mechanisms:**

```cpp
// Sample buffer pointer (audio thread reads, background thread writes)
std::atomic<juce::AudioBuffer<float>*> currentSampleBuffer { nullptr };

// Loading sample on background thread
void loadSampleAsync(const juce::File& file)
{
    std::thread([this, file]()
    {
        // Load sample (blocking file I/O - safe on background thread)
        auto formatManager = juce::AudioFormatManager();
        formatManager.registerBasicFormats();

        auto reader = formatManager.createReaderFor(file);
        if (reader == nullptr)
            return; // Invalid file

        // Create temporary buffer
        auto tempBuffer = std::make_unique<juce::AudioBuffer<float>>(
            reader->numChannels,
            static_cast<int>(reader->lengthInSamples)
        );

        // Read samples into buffer
        reader->read(tempBuffer.get(), 0, static_cast<int>(reader->lengthInSamples), 0, true, true);

        // Atomic swap (audio thread will see new buffer on next processBlock)
        auto oldBuffer = currentSampleBuffer.exchange(tempBuffer.release());

        // Delete old buffer on message thread (safe disposal)
        juce::MessageManager::callAsync([oldBuffer]() {
            delete oldBuffer;
        });

    }).detach();
}
```

**Safety guarantees:**
- Audio thread NEVER waits on file I/O (always reads from pre-loaded buffer)
- Audio thread uses lock-free atomic pointer read (zero contention)
- Background thread creates new buffer without touching audio thread data
- Atomic swap ensures audio thread sees either old or new buffer (never invalid state)
- Old buffer deleted on message thread (safe destruction outside audio thread)

**Parameter thread safety:**
- All APVTS parameters are inherently thread-safe (JUCE uses atomics internally)
- Audio thread: `auto* param = parameters.getRawParameterValue("GRAIN_SIZE"); float value = param->load();`
- Message thread: `parameters.getParameter("GRAIN_SIZE")->setValueNotifyingHost(newValue);`
- No custom synchronization needed (JUCE handles it)

---

## Implementation Risks

### Granular Engine Complexity

**Complexity:** HIGH
- Grain windowing, overlapping, density control, spacing multiplier
- Real-time grain generation and mixing
- Per-voice independent grain streams

**Risk Level:** MEDIUM

**Risk factors:**
1. Grain overlapping logic can cause CPU spikes if not managed properly
   - Many active grains (high density + large grain size) = high CPU
   - Need to limit max active grains per voice
2. Grain triggering timing must be sample-accurate for smooth texture
   - Timing jitter creates audible artifacts (irregular grain spacing)
3. Window function application must be efficient (per-sample multiplication)
   - Pre-calculated window tables prevent CPU waste

**Alternative approaches:**
1. **Simplified granular (no overlapping):**
   - Complexity: LOW
   - Quality: Lower (audible gaps between grains)
   - CPU: ~30% reduction
   - Best for: Prototype to validate concept

2. **Fixed grain count (no density parameter):**
   - Complexity: MEDIUM
   - Limitation: Less control over texture
   - CPU: Predictable (always same grain count)
   - Best for: Performance-critical scenarios

**Fallback architecture:**
- **Primary:** Full granular engine with overlap-add (highest quality)
- **Fallback 1:** Limit max grains per voice to 8 (reduce CPU if performance issues)
- **Fallback 2:** Simplified granular with no overlap (prototype only, not production)
- **Condition:** Fall back if CPU usage exceeds 80% single core with 8 voices active

**Mitigation strategy:**
1. Implement grain count limiting from start (max 8 active grains per voice)
2. Pre-calculate Hann window tables for common grain sizes (10ms, 25ms, 50ms, 100ms, 200ms, 500ms)
3. Use fixed-point arithmetic for grain phase tracking (faster than float modulo)
4. Profile CPU usage early (target <60% single core with 8 voices active)
5. Reference existing granular implementations (Mutable Instruments Clouds, Ableton Granulator)

---

### Sample Loading and Thread Safety

**Complexity:** MEDIUM
- Background thread file I/O
- Atomic buffer swapping
- Error handling for missing/invalid files

**Risk Level:** LOW

**Risk factors:**
1. Atomic pointer swap must be correct (audio thread reading while background thread swapping)
   - Risk: Rare race condition if swap happens mid-processBlock
   - Mitigation: std::atomic<T*> guarantees atomic load/store (safe)
2. File path persistence can break if file moved/deleted
   - Risk: Plugin restores with missing sample (silent output)
   - Mitigation: Show error in UI, allow user to re-load sample
3. Large files (60s at 192kHz = ~23MB per channel) can cause memory issues
   - Risk: Out-of-memory on systems with low RAM
   - Mitigation: Limit sample length to 60s, show warning if file truncated

**Alternative approaches:**
1. **Streaming playback (no full load):**
   - Complexity: HIGH
   - Benefit: Lower memory usage
   - Risk: Disk I/O in audio thread (unacceptable latency)
   - Best for: Very long samples (>5 minutes)

2. **Fixed sample pool (no user loading):**
   - Complexity: LOW
   - Limitation: No user samples (only bundled presets)
   - Best for: Simplified version

**Fallback architecture:**
- **Primary:** Full file loading with atomic swap (most flexible)
- **Fallback 1:** If memory issues arise → Limit sample length to 30s (reduce memory by half)
- **Fallback 2:** If file I/O proves problematic → Fixed sample pool with bundled samples
- **Condition:** Fall back if >10% of users report out-of-memory errors

**Mitigation strategy:**
1. Use `std::atomic<AudioBuffer<float>*>` for buffer pointer (JUCE best practice)
2. Test with large files (60s stereo at 192kHz) to verify memory handling
3. Implement file size checking before load (warn if >100MB)
4. Add UI loading indicator (show progress during background load)
5. Test restore behavior with missing files (error handling validation)

---

### Polyphonic Voice Management

**Complexity:** MEDIUM
- Voice allocation, stealing, mono/poly mode switching
- Per-voice grain state management
- Envelope triggering on note-off

**Risk Level:** LOW

**Risk factors:**
1. Voice stealing can cause audible clicks if release envelope not fast enough
   - Risk: Sudden cutoff sounds unnatural
   - Mitigation: 10ms release envelope on stolen voices
2. Mono mode legato behavior requires careful retrigger logic
   - Risk: Grain phase reset causes audible discontinuity
   - Mitigation: Smooth grain phase transition or retrigger with crossfade
3. High polyphony (16 voices) with complex grains can cause CPU overload
   - Risk: Audio dropouts (buffer underruns)
   - Mitigation: Limit max voices to 8 if CPU usage too high

**Alternative approaches:**
1. **Mono-only (no polyphony):**
   - Complexity: LOW
   - Limitation: Single voice playback only
   - CPU: Minimal (~5-10% single core)
   - Best for: Prototype, reduced-scope version

2. **Fixed polyphony (no mono mode):**
   - Complexity: MEDIUM
   - Limitation: Always polyphonic (no legato)
   - Best for: Simplified voice management

**Fallback architecture:**
- **Primary:** Full mono/poly switching with 16 voices (most flexible)
- **Fallback 1:** If CPU too high → Reduce max voices to 8 (still polyphonic)
- **Fallback 2:** If voice stealing causes artifacts → Mono-only mode
- **Condition:** Fall back if CPU exceeds 80% with 16 voices or voice stealing clicks audible

**Mitigation strategy:**
1. Follow JUCE `Synthesiser` pattern for voice management (well-tested architecture)
2. Implement fast release envelope (10ms) on all voice terminations
3. Test voice stealing with maximum polyphony (16 voices active, trigger 17th note)
4. Profile CPU usage with full polyphony (target <60% single core)
5. Add voice count display in UI (show active voices for debugging)

---

### Overall Project Risk

**Overall complexity:** MEDIUM-HIGH
- Granular engine (HIGH) + sample loading (MEDIUM) + voice management (MEDIUM)
- 3 moderately complex features with clear integration points

**Highest risk component:** Granular Engine
- Represents ~60% of project risk
- Most algorithmically complex (overlap-add, windowing, density control)
- Highest CPU cost (~40-60% single core with 8 voices active)
- Critical for plugin identity (core feature)

**Recommended approach:**
1. **Phase 1 - Validate concept:** Implement simplified granular (no overlap) + sample loading (MEDIUM risk)
   - Test: Load sample, play single grain on MIDI trigger, verify pitch shift works
2. **Phase 2 - Core granular:** Add overlap-add with Hann windowing (HIGH risk)
   - Test: Verify smooth texture, no clicks, CPU acceptable
3. **Phase 3 - Voice management:** Add polyphonic voice allocation (MEDIUM risk)
   - Test: 16-voice polyphony, voice stealing, mono mode legato
4. **Phase 4 - Optimization:** Profile and optimize CPU usage (LOW risk)
   - Test: CPU usage <60% with 8 voices active, no dropouts
5. **Phase 5 - Polish:** UI integration, waveform display, preset system (LOW risk)

---

## Architecture Decisions

### Granular Synthesis Algorithm Choice

**Decision:** Use overlap-add synthesis with time-domain pitch shifting (no FFT)

**Rationale:**
- Industry standard for granular samplers (Ableton Granulator, Reaktor Grain Delay)
- Time-domain approach is simpler than frequency-domain (no FFT/IFFT overhead)
- Grain windowing prevents artifacts that would occur with FFT pitch shifting
- Lower CPU cost than phase vocoder (~10-20% vs ~40-60%)
- Grain-based playback naturally supports pitch shift via playback rate adjustment

**Alternatives considered:**
1. **Phase vocoder (FFT-based pitch shift):**
   - Why rejected: Overkill for granular synthesis (grains already windowed), higher CPU cost
   - When to reconsider: If time-domain pitch shift has unacceptable artifacts at extreme shifts (±12 semitones)

2. **Wavetable synthesis (pre-rendered grains):**
   - Why rejected: No user sample loading (fixed waveforms only), loses granular character
   - When to reconsider: For bundled preset mode with fixed samples

3. **Tape-style varispeed (no windowing):**
   - Why rejected: Clicks and pops without windowing, not suitable for granular
   - When to reconsider: Never (fundamentally incompatible with granular synthesis)

**Tradeoffs accepted:**
- **Grain artifacts at extreme pitch shifts:** ±12 semitones may sound "grainy" vs smooth phase vocoder
  - Acceptable because: Granular synthesis is inherently "grainy" (not a bug, it's a feature)
- **No formant preservation:** Pitch shift changes timbre (voice samples sound "chipmunk-like" at +12)
  - Acceptable because: Granular samplers are for creative sound design, not realistic playback
- **CPU scales with polyphony:** 16 voices = 16x CPU vs 1 voice
  - Acceptable because: Target is studio use (not CPU-starved live scenarios), voice limiting available

**When to revisit:**
- If users report unacceptable artifacts at ±12 semitones (add phase vocoder option)
- If CPU usage exceeds 80% single core (reduce max voices or optimize grain rendering)
- If formant preservation is requested (add formant-corrected pitch shift mode)

---

### Sample Loading Architecture

**Decision:** Background thread loading with atomic buffer pointer swap (full sample in memory)

**Rationale:**
- Simplest thread-safe approach (atomic pointer swap, no locks)
- Full sample in memory enables instant grain extraction (no disk I/O latency)
- JUCE provides atomic utilities and thread management (proven patterns)
- Most granular samplers use this approach (Ableton Sampler, Kontakt)

**Alternatives considered:**
1. **Streaming playback (disk I/O per grain):**
   - Why rejected: Disk I/O in audio thread is unacceptable (causes dropouts), complex buffering
   - When to reconsider: If users load very long samples (>5 minutes) causing memory issues

2. **Lock-based buffer swap (mutex):**
   - Why rejected: Mutex in audio thread causes priority inversion (real-time violation)
   - When to reconsider: Never (lock-free atomics are superior for real-time audio)

3. **Fixed sample pool (bundled samples only):**
   - Why rejected: No user sample loading (major feature loss)
   - When to reconsider: For lite version or demo mode

**Tradeoffs accepted:**
- **Memory usage:** Full sample in memory (60s stereo at 192kHz = ~46MB)
  - Acceptable because: Modern systems have >8GB RAM, 46MB is negligible
  - Mitigation: Limit sample length to 60s, warn if truncating
- **Load latency:** Background loading takes 10-500ms (visible UI delay)
  - Acceptable because: Users expect sample loading to take time (not instant)
  - Mitigation: Show loading indicator in UI
- **File path dependencies:** Saved presets reference file paths (can break if file moved)
  - Acceptable because: Standard sampler behavior (Kontakt, Battery work same way)
  - Mitigation: Show error in UI if sample missing, allow re-load

**When to revisit:**
- If >10% of users report out-of-memory errors (add streaming playback option)
- If load latency >1 second is common (optimize sample rate conversion)
- If file path persistence is too fragile (add optional sample embedding in presets)

---

### Voice Management Design

**Decision:** Up to 16 polyphonic voices with mono/poly mode switching

**Rationale:**
- 16 voices is industry standard for polyphonic samplers (Kontakt, Battery)
- Mono mode enables legato playing style (common for basslines, leads)
- Voice stealing with release envelope prevents audible clicks
- Per-voice independent grain streams enable full polyphony (no shared grain state)

**Alternatives considered:**
1. **Unlimited polyphony (no voice limit):**
   - Why rejected: CPU can spike to 100% with many simultaneous notes (audio dropouts)
   - When to reconsider: If users frequently need >16 voices (rare in practice)

2. **Mono-only (no polyphony):**
   - Why rejected: Major feature loss (no chords, no layering)
   - When to reconsider: For simplified version or if polyphony causes excessive CPU usage

3. **Fixed polyphony count (no mono mode):**
   - Why rejected: Mono mode is valuable for legato playing (basslines, leads)
   - When to reconsider: If mono mode implementation proves complex or buggy

**Tradeoffs accepted:**
- **CPU scales with voices:** 16 voices = ~16x CPU usage vs 1 voice
  - Acceptable because: Most musical use doesn't sustain 16 voices simultaneously
  - Mitigation: Voice stealing limits active voices, profile to ensure <80% CPU with 16 voices
- **Voice stealing can cause clicks:** Stolen voice must release fast (10ms)
  - Acceptable because: 10ms release is fast enough to be inaudible in most contexts
  - Mitigation: Tune release envelope, test with aggressive voice stealing scenarios
- **Mono mode legato requires retrigger logic:** Grain phase must transition smoothly
  - Acceptable because: Legato is advanced feature (users understand it may have quirks)
  - Mitigation: Implement retrigger with optional crossfade if discontinuities audible

**When to revisit:**
- If CPU usage >80% with 16 voices active (reduce max voices to 8)
- If voice stealing clicks are audible (lengthen release envelope or add crossfade)
- If users request >16 voices (add user-configurable voice count setting)

---

## Special Considerations

### Thread Safety
- All APVTS parameters use atomic reads: `auto* param = parameters.getRawParameterValue("GRAIN_SIZE"); float value = param->load();`
- Sample buffer pointer is `std::atomic<AudioBuffer<float>*>` (lock-free load/store)
- No mutex in audio thread (audio thread only reads atomics, never blocks)
- Background thread performs file I/O safely (no interaction with audio thread during load)
- Old buffer deleted on message thread via `MessageManager::callAsync()` (safe disposal)

### Performance
- **Estimated CPU usage:**
  - Single voice: ~5-10% single core (grain generation, windowing, pitch shift)
  - 8 voices: ~40-60% single core (linear scaling)
  - 16 voices: ~80-100% single core (max polyphony, may need voice limiting)
- **Hot paths:**
  - Grain extraction with pitch shift (per-sample linear interpolation)
  - Hann window multiplication (pre-calculated tables reduce cost)
  - Voice summing (simple addition, minimal overhead)
- **Optimization opportunities:**
  - SIMD for window multiplication (process 4 samples at once with SSE)
  - Pre-calculated window tables (avoid repeated sin/cos calculations)
  - Fixed-point grain phase tracking (faster than float modulo)
  - Grain count limiting (max 8 active grains per voice)

### Denormal Protection
- Use `juce::ScopedNoDenormals` in `processBlock()` (flush denormals to zero)
- Grain envelopes naturally avoid denormals (Hann window always >0 in grain, =0 outside)
- Voice envelope release adds tiny DC offset before multiplication (prevents denormal creep)
- Linear interpolation handles denormals correctly (no special casing needed)

### Sample Rate Handling
- Sample rate dependent calculations (recalculated in `prepareToPlay()`):
  - Grain size: `grainSamples = (grainSizeMs / 1000.0) * sampleRate`
  - Density interval: `grainInterval = sampleRate / density`
  - Release envelope rate: `releaseRate = 1.0 / (0.01 * sampleRate)` (10ms)
- Hann window tables regenerated when grain size changes (size-dependent)
- Sample buffer resampled on load if sample rate != host rate (`juce::LagrangeInterpolator`)
- All time-based parameters are in milliseconds (independent of sample rate)

### Latency
- **Processing latency sources:**
  - Granular engine: ~0ms (no lookahead, grains extracted in real-time)
  - Pitch shift (time-domain): ~0ms (no FFT buffering)
  - Sample buffer read: ~0ms (pre-loaded in memory)
- **Total latency:** 0 samples (report via `getLatencySamples()` returns 0)
- **No host compensation needed:** Real-time granular processing has no inherent latency
- **Note:** MIDI note-on to audio output is sample-accurate (no buffering delay)

---

## Research References

### Professional Plugins

1. **Ableton Granulator II**
   - Classic granular synthesis device in Ableton Live
   - Parameter range: Grain size 5-500ms, density 1-200 grains/sec
   - Observed: Uses overlap-add synthesis with variable window shapes
   - Spray parameter similar to spacing (randomizes grain position)

2. **Native Instruments Reaktor (Grain Delay ensemble)**
   - Granular delay/sampler in Reaktor
   - Noted: Time-domain pitch shift via playback rate (no FFT)
   - Grain texture controlled by density and feedback

3. **Mutable Instruments Clouds (hardware/software granular processor)**
   - Eurorack granular processor
   - Observed: 4-voice polyphony typical for granular modules
   - Real-time grain generation with pitch/time manipulation
   - Uses overlap-add with Hann windowing

4. **Output Portal (granular effects plugin)**
   - Modern granular plugin
   - Grain size 1-500ms typical range
   - Real-time granular processing with low latency
   - Time-domain approach (no FFT artifacts)

### JUCE Documentation

- **juce::AudioFormatManager**: Sample loading and format detection
  - `registerBasicFormats()` for WAV/AIFF support
  - `createReaderFor(File)` creates format-specific reader
- **juce::AudioFormatReader**: Reading audio files into memory
  - `read(AudioBuffer, startSample, numSamples)` fills buffer
  - Handles multi-channel files, sample rate conversion
- **juce::dsp::WindowingFunction**: Pre-built window functions
  - `fillWindowingTables()` generates Hann, Hamming, Blackman windows
  - Used for grain envelope (Hann window recommended)
- **juce::Synthesiser**: Voice management pattern
  - `addVoice()`, `noteOn()`, `noteOff()` architecture
  - Good reference for polyphonic voice allocation
- **std::atomic**: Lock-free atomic operations
  - `std::atomic<T*>` for sample buffer pointer
  - `load()` / `store()` / `exchange()` for thread-safe pointer swapping

### Technical Resources

- **The Computer Music Tutorial** (Curtis Roads) - Granular synthesis chapter
  - Academic foundation for overlap-add synthesis
  - Window function selection (Hann window recommended for smooth grains)
- **Designing Audio Effect Plugins in C++** (Will Pirkle) - Sample playback chapter
  - Linear interpolation for fractional sample reads
  - Thread-safe buffer management patterns
- **DAFX (Digital Audio Effects)** - Pitch shifting chapter
  - Time-domain vs frequency-domain trade-offs
  - Playback rate formula: `rate = 2^(semitones/12)`

---

## Notes

- Chose time-domain pitch shift over phase vocoder (simpler, lower CPU, grain windowing masks artifacts)
- Hann window selected for grain envelope (smooth attack/release, minimal artifacts)
- Linear interpolation adequate for granular (grain windowing masks interpolation artifacts)
- 16-voice polyphony matches industry standard (Kontakt, Battery)
- Atomic buffer swap avoids mutex in audio thread (real-time safe)
- Region selection normalized (0.0-1.0) for sample-rate independence
- Spacing multiplier provides creative control over grain texture (overlap vs sparse)
- No dry/wet mix (instrument generates audio from scratch, not effect)
- Sample embedding optional (file path reference keeps preset size small)
- Voice count limiting may be needed if CPU usage too high (reduce from 16 to 8 voices)
